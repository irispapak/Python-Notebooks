{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Information\n",
    "* Please do not copy and paste solutions from other people, I would hate to give you 0 points. \n",
    "* You must not turn this in later then Wednesday at midnight. After this you will not be able to upload the file and you will get 0 points\n",
    "* Upload your results as a notebook with the title lastname_firstname_final.ipynb\n",
    "* On Thursday and Friday you will present your code and results. This should take about 10 minutes, no powerpoint required. \n",
    "* Use comments. Code without or bad comments will lose points. You do not have to comment every line. Just think about what comments your future self might find helpful.\n",
    "* You will get points for: \n",
    "    * a working solution (50 Points)\n",
    "    * your explanation of your code in the presentation (40 Points)\n",
    "    * good comments and code structure (5 Points)\n",
    "    * solving the problem with pandas (5 Points)\n",
    "* You can use this notebook for uploading or a python file, your choice. \n",
    "* The following tasks will make use of most things we learned in the course, so you should be able to do them all. They are possible without the use of pandas, but this will require a bit more elbow grease. \n",
    "* Do not start too late with this notebook. I guarantee you it will take some time.\n",
    "* For reference, my solution has a around 80 lines of code (including imports, header, comments and empty lines). \n",
    "* If an exercise is unclear or you find any mistakes, please contact me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Hint\n",
    "If you struggle with the tasks presented here, do not start banging your head against the wall. Take a step back, write down in normal english what you think your program should do. Then translate it to code. If you still struggle, take a look again at the exercises or look on the internet or books for new ones. Also, going for a walk and relaxing with something different like food or sports helps your head coming up with solution to programming problems on its own (just try it when you are stuck)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about the Data\n",
    "Together with this notebook I uploaded three files:\n",
    "* a pdf describing a landcover classification system\n",
    "* a txt file with a DEM and landcover information\n",
    "* a txt containing interpolated rainfall information for the DEM over several years [mm/day]\n",
    "\n",
    "## DEM/Land Cover File Structure\n",
    "Latitude, Longitude, Elevation, Landcover Type\n",
    "\n",
    "## Interpolated Rainfall File Structure\n",
    "Rows contain the values for a given point over the whole time period. Columns contain the values for all points for a given day. The row layout is equal to the DEM file. This means that the first row of the rainfall file contains the rainfall timeseries for the whole timeperiod for the point in the first row of the DEM file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Read in the DEM/land cover file. Replace the rather detailed land cover classes with a more coarse classification. A sensible choice would be woods, .. and so forth. Save the results in a new file. Do not retain the old classification in the new file, do not overwrite the old file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the DEM/land cover file\n",
    "filename = 'location_height_landcover.txt'\n",
    "dem_file = pd.read_csv(filename, sep=' ', header=None, names=['Latitude', 'Longitude', 'Elevation', 'Landcover Type'])\n",
    "\n",
    "# define the names of 5 classes of Landcover Type\n",
    "classes = ['Built-up Areas', 'Agricultural Areas', 'Forests and Natural Areas', 'Moist Areas', 'Water Surfaces']\n",
    "\n",
    "# keep only the column of Landcover Type that satisfies a condition\n",
    "class1 = dem_file['Landcover Type'][dem_file['Landcover Type']<200]\n",
    "class2 = dem_file['Landcover Type'][dem_file['Landcover Type']<300]\n",
    "class3 = dem_file['Landcover Type'][dem_file['Landcover Type']<400]\n",
    "class4 = dem_file['Landcover Type'][dem_file['Landcover Type']<500]\n",
    "class5 = dem_file['Landcover Type'][dem_file['Landcover Type']<600]\n",
    "\n",
    "# replace the name of the class in the column of Landcover Type\n",
    "dem_file['Landcover Type'].replace(class1, classes[0], inplace=True)\n",
    "dem_file['Landcover Type'].replace(class2, classes[1], inplace=True)\n",
    "dem_file['Landcover Type'].replace(class3, classes[2], inplace=True)\n",
    "dem_file['Landcover Type'].replace(class4, classes[3], inplace=True)\n",
    "dem_file['Landcover Type'].replace(class5, classes[4], inplace=True)\n",
    "\n",
    "# save into a new file\n",
    "dem_file.to_csv('location_height_landcover_modified.txt', sep=' ', header=None, index=False, float_format='%.3f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "The data in the DEM/land cover file and the rainfall file are meant to be together, as they describe the same points. Therefore create a new file containing the information from the file you created in task 1 and the rainfall file. Due to an error in the calculations all rainfall data is also too big by a factor of ten. Fix this error (round to two digits). Save the results in a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the modified DEM/land cover file\n",
    "filename = 'location_height_landcover_modified.txt'\n",
    "dem_file = pd.read_csv(filename, sep=' ', header=None, names=['Latitude', 'Longitude', 'Elevation', 'Landcover Type'])\n",
    "\n",
    "# read the interpolated rainfall file\n",
    "filename = 'interpolated_rainfall.txt'\n",
    "inter_rain = pd.read_csv(filename, sep=' ', header=None)\n",
    "\n",
    "# correct error of rainfall data by dividing with 10 and round to 2 digits\n",
    "inter_rain = round(inter_rain/10.0, 2)\n",
    "\n",
    "# concatenate files along columns\n",
    "dem_rain = pd.concat([dem_file, inter_rain], axis=1)\n",
    "\n",
    "# save the new dataframe into a new file\n",
    "dem_rain.to_csv('dem_rain_combined.txt', sep=' ', header=None, index=False, float_format='%.2f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Read in the file you created in task 2. Next create a timeseries containing a single rainfall value for every day for every combination of an elevation above or below 500 m and your landuse classes. Save the results in seperate files. In the end you should have two files for every landuse class you defined, one for the points above 500 m and one for the points below. One timeseries (e.g. wood above 500 m) could look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your solution does not have to look exactly the same. This is just a made up example.\n",
    "\n",
    "Index \tWood above 500 m\n",
    "Day 1 \t0.2\n",
    "Day 2 \t0.5\n",
    "Day 3 \t1.0\n",
    "Day 4 \t0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/irida/Git/Python/task3/Agricultural Areas_Above_500m.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-111cd585fda2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# save one file for above 500m and one for below 500m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0marea\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_Above_500m.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marea\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Above 500m'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.2f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0marea\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_Below_500m.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marea\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Below 500m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.2f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path, index, sep, na_rep, float_format, header, index_label, mode, encoding, compression, date_format, decimal)\u001b[0m\n\u001b[1;32m   3779\u001b[0m                            \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3780\u001b[0m                            \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3781\u001b[0;31m                            date_format=date_format, decimal=decimal)\n\u001b[0m\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/irida/Git/Python/task3/Agricultural Areas_Above_500m.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# read the combined interpolated rainfall file\n",
    "filename = 'dem_rain_combined.txt'\n",
    "index = ['Day'+str(i) for i in range(1,10958)]\n",
    "dem_rain = pd.read_csv(filename, sep=' ', header=None, names=['Latitude', 'Longitude', 'Elevation', 'Landcover Type']+index)\n",
    "\n",
    "# seperate data with elevation > 500m and <500m respectively\n",
    "above_500 = dem_rain[dem_rain['Elevation']>500]\n",
    "below_500 = dem_rain[dem_rain['Elevation']<=500]\n",
    "\n",
    "# group data with elevation above 500m by Landcover Type \n",
    "above_500 = above_500.groupby('Landcover Type')\n",
    "# find the mean of these data\n",
    "rain_above_500 = above_500[index].mean()\n",
    "\n",
    "# group data with elevation below 500m by Landcover Type\n",
    "below_500 = below_500.groupby('Landcover Type')\n",
    "# find mean of these data\n",
    "rain_below_500 = below_500[index].mean()\n",
    "\n",
    "# set path of files\n",
    "path = os.getcwd()+ '/task3/'\n",
    "#print(path)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    # take every class that contains all days\n",
    "    above = rain_above_500.iloc[i,:]\n",
    "    below = rain_below_500.iloc[i,:]\n",
    "\n",
    "    # names of classes\n",
    "    area = rain_above_500.index[i]\n",
    "\n",
    "    # save one file for above 500m and one for below 500m. \n",
    "    above.to_csv(path+area +'_Above_500m.txt', sep=' ', header=[area + ' Above 500m' ], index=True, float_format='%.2f')\n",
    "    below.to_csv(path+area +'_Below_500m.txt', sep=' ', header=[area + ' Below 500m'], index=True, float_format='%.2f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Create a figure that shows the frequency distribution of the values for every time series you created in task 3 in a seperate subplot. Save the figure as a png and make certain you have a good data ink ratio and labelled everything correctly. \n",
    "\n",
    "Think about the different possibilities to display a frequency distribution. You should be able to give a short explanation for your choice of figure. Also, explain what insights the figure could give you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = []\n",
    "path = os.getcwd()+ '/task3/'\n",
    "\n",
    "# search all files in path and put them into df\n",
    "for file in sorted(os.listdir(path)):\n",
    "    df.append(pd.read_csv(path+file, sep=' ', header=0, index_col=0))\n",
    "\n",
    "# start of plot\n",
    "#--------------------\n",
    "bins=20\n",
    "titles = ['Agricultural Areas', 'Built-up Areas','Forests and Natural Areas']\n",
    "\n",
    "# create the subplots\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, sharey=True)\n",
    "\n",
    "# main title of graph\n",
    "fig.suptitle('Histogram of Rainfall', fontsize=12, fontweight='bold')\n",
    "\n",
    "# common x,y axes' titles\n",
    "fig.text(0.5, 0.01, 'Classes', ha='center')\n",
    "fig.text(0.001, 0.5, 'Frequency', va='center', rotation='vertical')\n",
    "\n",
    "# loop for all subplots\n",
    "for j in range(3):\n",
    "    for i in range(2):\n",
    "        if j==0:\n",
    "            \n",
    "            # create two histograms of the 1st column\n",
    "            ax[i,j].hist(x=df[i+j].values, bins=bins, rwidth=0.8, color='red')\n",
    "\n",
    "            # set limits of x axis\n",
    "            ax[i,j].set_xlim(0,80) \n",
    "            # set fontsize of x, y labels\n",
    "            ax[i,j].xaxis.set_tick_params(labelsize=8)\n",
    "            ax[i,j].yaxis.set_tick_params(labelsize=8)\n",
    "            \n",
    "        elif j==1:\n",
    "            \n",
    "            # create two histograms of the 2nd column\n",
    "            ax[i,j].hist(x=df[i+j+1].values, bins=bins, rwidth=0.8, color='grey')\n",
    "            \n",
    "            # set limits of x axis\n",
    "            ax[i,j].set_xlim(0,80)\n",
    "            # set fontsize of x, y labels\n",
    "            ax[i,j].xaxis.set_tick_params(labelsize=8)\n",
    "            ax[i,j].yaxis.set_tick_params(labelsize=8)\n",
    "            \n",
    "            # set titles for the first and second row of plots\n",
    "            if i==0:\n",
    "                ax[i,j].set_title('Above 500m', fontsize=10)\n",
    "            elif i==1:\n",
    "                ax[i,j].set_title('Below 500m', fontsize=10)\n",
    "           \n",
    "        elif j==2:\n",
    "            \n",
    "            # create two histograms of the 3rd column\n",
    "            ax[i,j].hist(x=df[i+j+2].values, bins=bins, rwidth=0.8, color='green')\n",
    "            \n",
    "            # set limits of x axis\n",
    "            ax[i,j].set_xlim(0,80)\n",
    "            # set fontsize of x, y labels\n",
    "            ax[i,j].xaxis.set_tick_params(labelsize=8)\n",
    "            ax[i,j].yaxis.set_tick_params(labelsize=8)\n",
    "\n",
    "# set legend for plot         \n",
    "fig.legend(titles, loc='upper right', fontsize=7)\n",
    "\n",
    "# correct potential crops\n",
    "fig.tight_layout()\n",
    "# shift title to the top\n",
    "fig.subplots_adjust(top=0.88)\n",
    "\n",
    "# save plot \n",
    "plt.savefig('Histogram_of_Rainfall.png', dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
